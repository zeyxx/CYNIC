# CYNIC v2 - Plan d'Impl√©mentation Unifi√©

## üéØ Vision
CYNIC = Agent + IDE + Orchestrateur + Mod√®le + OS

## ‚ö†Ô∏è Principe Fondamental
**RIEN N'EST Gratuit** - CYNIC conna√Æt les co√ªts r√©els

- Claude Code: $20/mois (subscription)
- Ollama: GPU electricity + hardware amortized
- API providers: prix r√©el par token
- AirLLM: SSD I/O + CPU costs

---

## üìã Todo List

### Phase 1: LLM Layer (Intelligent Switch)
- [x] 1.1 Unifier les adapters (4‚Üí1 intelligent switch) ‚úÖ DONE
- [x] 1.2 Ajouter WebSocketClaudeAdapter ‚úÖ DONE
- [ ] 1.3 Impl√©menter OllamaClaudeAdapter (Anthropic API compatible)
- [x] 1.4 Intelligent Switch avec REAL pricing ‚úÖ DONE
- [x] 1.5 PricingOracle - co√ªts temps r√©el ‚úÖ DONE

### Phase 2: Retrieval Layer
- [x] 2.1 Ajouter PageIndex reasoning-based retrieval ‚úÖ DONE
- [ ] 2.2 Cr√©er hybrid: Qdrant + PageIndex

### Phase 3: Orchestration Layer
- [ ] 3.1 Impl√©menter Prometheus pattern (planning)
- [ ] 3.2 Impl√©menter Atlas pattern (execution)
- [ ] 3.3 Int√©grer avec KabbalisticRouter existant

### Phase 4: Learning Layer (Fine-tuning)
- [ ] 4.1 Cr√©er pipeline dataset depuis learning events
- [ ] 4.2 Impl√©menter LoRA fine-tuning
- [ ] 4.3 Connecter adapter weights √† CYNIC

### Phase 5: Infra
- [ ] 5.1 WebSocket server complet
- [ ] 5.2 CLI unifi√©
- [ ] 5.3 Docker optimization

---

## üîó Inspirations
- Vibe Companion (WebSocket protocol)
- PageIndex (reasoning-based RAG)
- oh-my-opencode (Prometheus‚ÜíAtlas)
- LoRA/QLoRA (fine-tuning sans GPU)
